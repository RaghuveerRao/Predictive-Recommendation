{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "train_rf_df = spark.read.format(\"csv\") \\\n                .option('header', True) \\\n                .option('inferSchema', True) \\\n                .load(\"s3://raghu18/trends/df_train4.csv\")\n\n\n", "execution_count": 2, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "x_test = spark.read.format(\"csv\") \\\n                .option('header', True) \\\n                .option('inferSchema', True) \\\n                .load(\"s3://raghu18/trends/df_test.csv\")", "execution_count": 3, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "from pyspark.ml import Pipeline\nfrom pyspark.ml.classification import RandomForestClassifier as RF\nfrom pyspark.ml.regression import RandomForestRegressor as RF_reg\nfrom pyspark.ml.feature import StringIndexer, VectorIndexer, VectorAssembler, SQLTransformer\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nimport numpy as np\nimport functools\nfrom pyspark.ml.feature import OneHotEncoder\n#import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}\nfrom pyspark.ml.evaluation import RegressionEvaluator\n", "execution_count": 4, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# prepare labeled sets    Train\ncols_now = ['user_total_orders', 'user_total_items', 'total_distinct_items',\n       'user_average_days_between_orders', 'user_average_basket',\n       'order_hour_of_day', 'days_since_prior_order', 'days_since_ratio',\n       'aisle_id', 'department_id', 'product_orders', 'product_reorders',\n       'product_reorder_rate', 'UP_orders', 'UP_orders_ratio',\n       'UP_average_pos_in_cart', 'UP_reorder_rate', 'UP_orders_since_last',\n       'UP_delta_hour_vs_last']\nassembler_features = VectorAssembler(inputCols=cols_now, outputCol='features')\nlabel_indexer = StringIndexer(inputCol='label', outputCol='label_double')\npipeline_train = Pipeline(stages=[assembler_features, label_indexer])", "execution_count": 5, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# prepare labeled sets     x_test\ncols_now = ['user_total_orders', 'user_total_items', 'total_distinct_items',\n       'user_average_days_between_orders', 'user_average_basket',\n       'order_hour_of_day', 'days_since_prior_order', 'days_since_ratio',\n       'aisle_id', 'department_id', 'product_orders', 'product_reorders',\n       'product_reorder_rate', 'UP_orders', 'UP_orders_ratio',\n       'UP_average_pos_in_cart', 'UP_reorder_rate', 'UP_orders_since_last',\n       'UP_delta_hour_vs_last']\nassembler_features = VectorAssembler(inputCols=cols_now, outputCol='features')\npipeline_test = Pipeline(stages=[assembler_features])", "execution_count": 6, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "trainData = pipeline_train.fit(train_rf_df).transform(train_rf_df)\n\ntestData = pipeline_test.fit(x_test).transform(x_test)", "execution_count": 7, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Grid search\nrf = RF(labelCol='label_double', featuresCol='features')\nparamGrid = ParamGridBuilder() \\\n    .addGrid(rf.numTrees, [1, 2]) \\\n    .addGrid(rf.maxDepth, [2]) \\\n    .addGrid(rf.maxBins, [2]) \\\n    .build()\npipeline = Pipeline([rf])\n\ncrossval = CrossValidator(estimator=pipeline,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=RegressionEvaluator(),\n                          numFolds=4)  # use 3+ folds in practice\n", "execution_count": 12, "outputs": [{"output_type": "stream", "text": "Method __init__ forces keyword arguments.\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/__init__.py\", line 103, in wrapper\n    raise TypeError(\"Method %s forces keyword arguments.\" % func.__name__)\nTypeError: Method __init__ forces keyword arguments.\n\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "cvModel = crossval.fit(training)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rf = RF_reg(labelCol='label_double', featuresCol='features',numTrees=30, maxDepth=10, maxBins=100)\nfit = rf.fit(trainData)\n# transformed = fit.transform(testData)", "execution_count": 13, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "transformed = fit.transform(testData)", "execution_count": 14, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "testData.show(2)", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "+---+--------+----------+-----------------+----------------+--------------------+--------------------------------+-------------------+-----------------+----------------------+----------------+--------+-------------+--------------+----------------+--------------------+---------+---------------+----------------------+---------------+--------------------+---------------------+------------------+--------------------+\n|_c0|order_id|product_id|user_total_orders|user_total_items|total_distinct_items|user_average_days_between_orders|user_average_basket|order_hour_of_day|days_since_prior_order|days_since_ratio|aisle_id|department_id|product_orders|product_reorders|product_reorder_rate|UP_orders|UP_orders_ratio|UP_average_pos_in_cart|UP_reorder_rate|UP_orders_since_last|UP_delta_hour_vs_last|              pred|            features|\n+---+--------+----------+-----------------+----------------+--------------------+--------------------------------+-------------------+-----------------+----------------------+----------------+--------+-------------+--------------+----------------+--------------------+---------+---------------+----------------------+---------------+--------------------+---------------------+------------------+--------------------+\n|  0| 2774568|     17668|               13|              88|                  33|                            12.0|           6.769231|               15|                  11.0|       0.9166667|      91|           16|          2110|          1220.0|            0.578199|        5|      0.3846154|                   3.6|      0.3846154|                   2|                    3|0.3228918787898133|[13.0,88.0,33.0,1...|\n|  1| 2774568|     44683|               13|              88|                  33|                            12.0|           6.769231|               15|                  11.0|       0.9166667|      83|            4|         22275|         11981.0|          0.53786755|        2|     0.15384616|                   9.5|     0.15384616|                   7|                    1| 0.082390009405112|[13.0,88.0,33.0,1...|\n+---+--------+----------+-----------------+----------------+--------------------+--------------------------------+-------------------+-----------------+----------------------+----------------+--------+-------------+--------------+----------------+--------------------+---------+---------------+----------------------+---------------+--------------------+---------------------+------------------+--------------------+\nonly showing top 2 rows", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "result = transformed.select(['order_id', 'product_id', 'pred'])", "execution_count": 17, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "from io import StringIO\nimport boto3\n\ncsv_buffer = StringIO()\nresult.to_csv(csv_buffer)\ns3_resource = boto3.resource('s3')\ns3_resource.Object(bucket, 'df.csv').put(Body=csv_buffer.getvalue())", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "No module named boto3\nTraceback (most recent call last):\nImportError: No module named boto3\n\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "result.write.save(\"s3://raghu18/trends/file.csv\", format='csv', header=True)", "execution_count": 20, "outputs": []}], "metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": ""}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 2}, "pygments_lexer": "python2"}}, "nbformat": 4, "nbformat_minor": 2}